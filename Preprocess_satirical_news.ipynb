{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocess satirical news",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "11v9UIMSmbReRpdUXld_6Po1DlmB1cpjL",
      "authorship_tag": "ABX9TyNgYRbIIYZRHZ0hKspRaNxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cllaire/Cariere/blob/master/Preprocess_satirical_news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO-TTs0UbL55"
      },
      "source": [
        "This colab aims to preprocess the dataset for satirical and non-satirical news. The two types of preprocessing that we're going to do is:\n",
        "* replace named entities with a distinct symbol \n",
        "* eliminate tags such as new lines/tabs/multiple spaces\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHweVvxEbCii"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "import math"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nZHpe1Nb6NB"
      },
      "source": [
        "REPLACE_ENTITY = \"$NE$\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Alk_C1f8tU"
      },
      "source": [
        "def replace_named_entities(text):\n",
        "  # Get all tokens split by space. \n",
        "  tokens = re.split(\" \", text)\n",
        "  # Replace uppercase tokens that don't follow full-stop with $NE$. \n",
        "  replaced_tokens = []\n",
        "  for index in range(len(tokens)):\n",
        "    if index == 0:\n",
        "      replaced_tokens.append(tokens[index])\n",
        "      continue\n",
        "    if tokens[index] is not \"\" and tokens[index-1] is not \"\":\n",
        "      if tokens[index][0].isupper() and tokens[index-1][-1] is not '.':\n",
        "        if tokens[index][-1] == '.':\n",
        "          replaced_tokens.append(REPLACE_ENTITY + '.')\n",
        "        else:\n",
        "          replaced_tokens.append(REPLACE_ENTITY)\n",
        "        continue\n",
        "      if len(tokens[index]) > 1 and tokens[index][1].isupper():\n",
        "        replaced_tokens.append(REPLACE_ENTITY)\n",
        "        continue\n",
        "    replaced_tokens.append(tokens[index])\n",
        "\n",
        "  # Replace sequence of $NE$ with only one $NE$. \n",
        "  current_len = 0\n",
        "  simplified_tokens = []\n",
        "  for token in replaced_tokens:\n",
        "    if token == REPLACE_ENTITY:\n",
        "      current_len += 1\n",
        "    else:\n",
        "      if current_len > 0:\n",
        "        simplified_tokens.append(REPLACE_ENTITY)\n",
        "        current_len = 0\n",
        "      simplified_tokens.append(token)\n",
        "  if current_len > 0:\n",
        "    simplified_tokens.append(REPLACE_ENTITY)\n",
        "  \n",
        "  return ' '.join(simplified_tokens)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO9MzvVaoBcu"
      },
      "source": [
        "def replace_tags(text):\n",
        "  try: \n",
        "    text = text.replace('\\t',' ') # Remove tab tag.\n",
        "  except:\n",
        "    print(text)\n",
        "  text = text.replace('\\n', ' ') # Remove new line tag.\n",
        "  text = text.replace('\\s', ' ') # Remove \\s tag.\n",
        "  text = text.replace('\\xa0',  ' ') # Remove \\xa0 tag.\n",
        "  text = re.sub(' +', ' ', text) # Replace multiple spaces with one space. \n",
        "  return text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxWnPRrsbw_4"
      },
      "source": [
        "# Retrieve data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyIU80wWdmqN"
      },
      "source": [
        "file_paths = glob.glob('/content/drive/My Drive/data/*/*/*.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md1uSBS6v2tY",
        "outputId": "1ae2db09-aec0-4d90-f40f-e3faed9a602f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for path in file_paths:\n",
        "  datasource = pd.read_csv(path)\n",
        "  print('Read:', path)\n",
        "  for index in range(len(datasource)):\n",
        "    if pd.isna(datasource['title'][index]) or pd.isna(datasource['content'][index]):\n",
        "      datasource.drop(index)\n",
        "      continue\n",
        "    datasource['title'][index] = replace_named_entities(replace_tags(datasource['title'][index])) \n",
        "    datasource['content'][index] = replace_named_entities(replace_tags(datasource['content'][index]))\n",
        "  new_path = path[:-4] + '_preprocessed.csv'\n",
        "  print('Write:', new_path)\n",
        "  datasource.to_csv(new_path)\n",
        "  print('No. samples:', len(datasource))  \n",
        "  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read: /content/drive/My Drive/data/non-satirical/mediafax/economic.csv\n",
            "Write: /content/drive/My Drive/data/non-satirical/mediafax/economic_preprocessed.csv\n",
            "No. samples: 492\n",
            "Read: /content/drive/My Drive/data/non-satirical/mediafax/social.csv\n",
            "Write: /content/drive/My Drive/data/non-satirical/mediafax/social_preprocessed.csv\n",
            "No. samples: 720\n",
            "Read: /content/drive/My Drive/data/non-satirical/mediafax/externe.csv\n",
            "Write: /content/drive/My Drive/data/non-satirical/mediafax/externe_preprocessed.csv\n",
            "No. samples: 705\n",
            "Read: /content/drive/My Drive/data/non-satirical/mediafax/politic.csv\n",
            "Write: /content/drive/My Drive/data/non-satirical/mediafax/politic_preprocessed.csv\n",
            "No. samples: 693\n",
            "Read: /content/drive/My Drive/data/non-satirical/digi/actualitate.csv\n",
            "Write: /content/drive/My Drive/data/non-satirical/digi/actualitate_preprocessed.csv\n",
            "No. samples: 2990\n",
            "Read: /content/drive/My Drive/data/non-satirical/digi/economie.csv\n",
            "Write: /content/drive/My Drive/data/non-satirical/digi/economie_preprocessed.csv\n",
            "No. samples: 2990\n",
            "Read: /content/drive/My Drive/data/non-satirical/digi/externe.csv\n",
            "Write: /content/drive/My Drive/data/non-satirical/digi/externe_preprocessed.csv\n",
            "No. samples: 2990\n",
            "Read: /content/drive/My Drive/data/non-satirical/digi/sport.csv\n",
            "Write: /content/drive/My Drive/data/non-satirical/digi/sport_preprocessed.csv\n",
            "No. samples: 1820\n",
            "Read: /content/drive/My Drive/data/non-satirical/digi/magazin.csv\n",
            "Write: /content/drive/My Drive/data/non-satirical/digi/magazin_preprocessed.csv\n",
            "No. samples: 240\n",
            "Read: /content/drive/My Drive/data/satirical/catavencii/actual.csv\n",
            "Write: /content/drive/My Drive/data/satirical/catavencii/actual_preprocessed.csv\n",
            "No. samples: 12126\n",
            "Read: /content/drive/My Drive/data/satirical/catavencii/investigatii.csv\n",
            "Write: /content/drive/My Drive/data/satirical/catavencii/investigatii_preprocessed.csv\n",
            "No. samples: 1908\n",
            "Read: /content/drive/My Drive/data/satirical/catavencii/fakebook.csv\n",
            "Write: /content/drive/My Drive/data/satirical/catavencii/fakebook_preprocessed.csv\n",
            "No. samples: 3158\n",
            "Read: /content/drive/My Drive/data/satirical/catavencii/reportaj-interviu.csv\n",
            "Write: /content/drive/My Drive/data/satirical/catavencii/reportaj-interviu_preprocessed.csv\n",
            "No. samples: 2131\n",
            "Read: /content/drive/My Drive/data/satirical/catavencii/cultura.csv\n",
            "Write: /content/drive/My Drive/data/satirical/catavencii/cultura_preprocessed.csv\n",
            "No. samples: 2143\n",
            "Read: /content/drive/My Drive/data/satirical/kmkz/serioase.csv\n",
            "Write: /content/drive/My Drive/data/satirical/kmkz/serioase_preprocessed.csv\n",
            "No. samples: 131\n",
            "Read: /content/drive/My Drive/data/satirical/kmkz/de-râs.csv\n",
            "Write: /content/drive/My Drive/data/satirical/kmkz/de-râs_preprocessed.csv\n",
            "No. samples: 3000\n",
            "Read: /content/drive/My Drive/data/satirical/academia_catavencu/actualitate.csv\n",
            "Write: /content/drive/My Drive/data/satirical/academia_catavencu/actualitate_preprocessed.csv\n",
            "No. samples: 3950\n",
            "Read: /content/drive/My Drive/data/satirical/academia_catavencu/cultura.csv\n",
            "Write: /content/drive/My Drive/data/satirical/academia_catavencu/cultura_preprocessed.csv\n",
            "No. samples: 706\n",
            "Read: /content/drive/My Drive/data/satirical/academia_catavencu/politic.csv\n",
            "Write: /content/drive/My Drive/data/satirical/academia_catavencu/politic_preprocessed.csv\n",
            "No. samples: 1320\n",
            "Read: /content/drive/My Drive/data/satirical/academia_catavencu/proiecte-speciale.csv\n",
            "Write: /content/drive/My Drive/data/satirical/academia_catavencu/proiecte-speciale_preprocessed.csv\n",
            "No. samples: 317\n",
            "Read: /content/drive/My Drive/data/satirical/academia_catavencu/social.csv\n",
            "Write: /content/drive/My Drive/data/satirical/academia_catavencu/social_preprocessed.csv\n",
            "No. samples: 2598\n",
            "Read: /content/drive/My Drive/data/satirical/academia_catavencu/sport.csv\n",
            "Write: /content/drive/My Drive/data/satirical/academia_catavencu/sport_preprocessed.csv\n",
            "No. samples: 270\n",
            "Read: /content/drive/My Drive/data/satirical/academia_catavencu/it.csv\n",
            "Write: /content/drive/My Drive/data/satirical/academia_catavencu/it_preprocessed.csv\n",
            "No. samples: 133\n",
            "Read: /content/drive/My Drive/data/satirical/academia_catavencu/monden.csv\n",
            "Write: /content/drive/My Drive/data/satirical/academia_catavencu/monden_preprocessed.csv\n",
            "No. samples: 645\n",
            "Read: /content/drive/My Drive/data/satirical/tnr/it-stiinta.csv\n",
            "Write: /content/drive/My Drive/data/satirical/tnr/it-stiinta_preprocessed.csv\n",
            "No. samples: 1234\n",
            "Read: /content/drive/My Drive/data/satirical/tnr/sport.csv\n",
            "Write: /content/drive/My Drive/data/satirical/tnr/sport_preprocessed.csv\n",
            "No. samples: 6\n",
            "Read: /content/drive/My Drive/data/satirical/tnr/monden.csv\n",
            "Write: /content/drive/My Drive/data/satirical/tnr/monden_preprocessed.csv\n",
            "No. samples: 3576\n",
            "Read: /content/drive/My Drive/data/satirical/tnr/life-death.csv\n",
            "Write: /content/drive/My Drive/data/satirical/tnr/life-death_preprocessed.csv\n",
            "No. samples: 3582\n",
            "Read: /content/drive/My Drive/data/satirical/tnr/politic.csv\n",
            "Write: /content/drive/My Drive/data/satirical/tnr/politic_preprocessed.csv\n",
            "No. samples: 3126\n",
            "Read: /content/drive/My Drive/data/satirical/tnr/cronica-de-film.csv\n",
            "Write: /content/drive/My Drive/data/satirical/tnr/cronica-de-film_preprocessed.csv\n",
            "No. samples: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Read: /content/drive/My Drive/data/satirical/ghimpele/lifestyle.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/lifestyle_preprocessed.csv\n",
            "No. samples: 36\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/justitie.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/justitie_preprocessed.csv\n",
            "No. samples: 22\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/economie.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/economie_preprocessed.csv\n",
            "No. samples: 32\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/turism.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/turism_preprocessed.csv\n",
            "No. samples: 35\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/politica.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/politica_preprocessed.csv\n",
            "No. samples: 36\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/actual.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/actual_preprocessed.csv\n",
            "No. samples: 135\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/auto.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/auto_preprocessed.csv\n",
            "No. samples: 30\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/divertisment.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/divertisment_preprocessed.csv\n",
            "No. samples: 25\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/locale.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/locale_preprocessed.csv\n",
            "No. samples: 55\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/monden.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/monden_preprocessed.csv\n",
            "No. samples: 71\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/sanatate.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/sanatate_preprocessed.csv\n",
            "No. samples: 54\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/international.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/international_preprocessed.csv\n",
            "No. samples: 149\n",
            "Read: /content/drive/My Drive/data/satirical/ghimpele/sport.csv\n",
            "Write: /content/drive/My Drive/data/satirical/ghimpele/sport_preprocessed.csv\n",
            "No. samples: 28\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}